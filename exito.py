import streamlit as st
import requests
from urllib.parse import urlparse
import matplotlib.pyplot as plt
import re
from io import BytesIO

# ============================================
# Funciones Auxiliares
# ============================================

def parse_number(text):
    """
    Funci√≥n para parsear n√∫meros con diferentes formatos.
    Convierte cadenas de texto a n√∫meros flotantes.
    """
    text = re.sub(r'[^\d.,]', '', text)
    if text.count(',') > text.count('.'):
        text = text.replace('.', '').replace(',', '.')
    else:
        text = text.replace(',', '')
    try:
        return float(text)
    except ValueError:
        return None

@st.cache_data(show_spinner=False)
def obtener_busqueda_serper(query, api_key):
    """
    Funci√≥n para obtener resultados de b√∫squeda utilizando la API de Serper.
    Retorna una lista de URLs encontradas en los resultados de b√∫squeda.
    """
    serper_url = "https://google.serper.dev/search"
    headers_serper = {
        "X-API-KEY": api_key,
        "Content-Type": "application/json"
    }
    data_serper = {"q": query}
    response_serper = requests.post(serper_url, headers=headers_serper, json=data_serper, timeout=10)
    response_serper.raise_for_status()
    search_results = response_serper.json()
    urls = []
    if "organic" in search_results:
        for item in search_results["organic"]:
            if "link" in item:
                urls.append(item["link"])
    return urls if urls else []

@st.cache_data(show_spinner=False)
def obtener_analisis_together(search_summary, api_key):
    """
    Funci√≥n para obtener an√°lisis detallado utilizando la API de Together.
    Retorna el contenido del an√°lisis.
    """
    together_url = "https://api.together.xyz/v1/chat/completions"
    headers_together = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    messages = [
        {
            "role": "system",
            "content": (
                "Eres un experto en an√°lisis de plataformas digitales con un enfoque en las demandas del mercado actual. "
                "Proporciona una evaluaci√≥n detallada del potencial de √©xito de la plataforma digital basada en la siguiente informaci√≥n. "
                "Incluye recomendaciones sobre aspectos de forma (dise√±o, usabilidad, interfaz) y fondo (funcionalidades, contenido, estrategia de mercado), se√±alando lo que sobra y lo que falta. "
                "Adem√°s, expresa el potencial de √©xito en t√©rminos de porcentaje, proporciona una estimaci√≥n del m√°ximo de visitantes al d√≠a y un resumen ejecutivo de los hallazgos clave."
                "\n\n"
                "Nota: La estimaci√≥n de visitantes diarios se basa en la versi√≥n mejorada de la plataforma, incorporando los cambios sugeridos."
            )
        },
        {
            "role": "user",
            "content": f"Aqu√≠ hay informaci√≥n sobre la plataforma: {search_summary}"
        }
    ]
    data_together = {
        "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "messages": messages,
        "max_tokens": 2512,
        "temperature": 0.7,
        "top_p": 0.7,
        "top_k": 50,
        "repetition_penalty": 1,
        "stop": ["<|eot_id|>"],
        "stream": False
    }

    response_together = requests.post(together_url, headers=headers_together, json=data_together, timeout=30)
    response_together.raise_for_status()
    analysis = response_together.json()
    if "choices" in analysis and len(analysis["choices"]) > 0:
        return analysis["choices"][0]["message"]["content"]
    else:
        raise ValueError("Respuesta inesperada de Together API.")

def generar_graficas(secciones):
    """
    Funci√≥n para generar las gr√°ficas necesarias basadas en las secciones del an√°lisis.
    Retorna un diccionario con el t√≠tulo de la secci√≥n y el buffer de la imagen.
    """
    plots = {}
    # Potencial de √âxito
    if "Potencial de √âxito" in secciones:
        porcentaje_val = parse_number(secciones["Potencial de √âxito"])
        if porcentaje_val is not None:
            fig, ax = plt.subplots(figsize=(2, 2))
            ax.pie([porcentaje_val, 100 - porcentaje_val], colors=['#4CAF50', '#CCCCCC'], startangle=90, counterclock=False)
            ax.axis('equal')
            buf = BytesIO()
            plt.savefig(buf, format='png', bbox_inches='tight')
            plt.close(fig)
            buf.seek(0)
            plots["Potencial de √âxito"] = buf

    # Estimaci√≥n de Visitantes Diarios
    if "Estimaci√≥n de Visitantes Diarios" in secciones:
        est_visitors_val = parse_number(secciones["Estimaci√≥n de Visitantes Diarios"])
        if est_visitors_val is not None:
            est_visitors_val = int(est_visitors_val)
            fig, ax = plt.subplots(figsize=(4, 1))
            ax.barh([''], [est_visitors_val], color='#4CAF50')
            ax.set_xlim(0, est_visitors_val * 1.2)
            ax.set_xlabel('N√∫mero de Visitantes')
            ax.set_yticks([])
            plt.tight_layout()
            buf = BytesIO()
            plt.savefig(buf, format='png', bbox_inches='tight')
            plt.close(fig)
            buf.seek(0)
            plots["Estimaci√≥n de Visitantes Diarios"] = buf

    return plots

def extraer_subdominios(domain, serper_api_key):
    """
    Funci√≥n para extraer subdominios utilizando la API de Serper.
    Retorna una lista de subdominios √∫nicos.
    """
    query = f"site:{domain}"
    urls = obtener_busqueda_serper(query, serper_api_key)
    subdominios_unicos = set()

    for url in urls:
        parsed_url = urlparse(url)
        subdomain = parsed_url.netloc
        if subdomain and subdomain != domain:
            subdominios_unicos.add(subdomain)

    return list(subdominios_unicos)

# ============================================
# Aplicaci√≥n Streamlit
# ============================================

def main():
    # T√≠tulo de la aplicaci√≥n
    st.title("üìà An√°lisis de Potencial de √âxito de Plataformas Digitales")

    # Descripci√≥n de la aplicaci√≥n
    st.markdown("""
    Esta aplicaci√≥n analiza el potencial de √©xito de una plataforma digital basada en su URL. Utiliza las APIs de Serper para obtener informaci√≥n relevante sobre la plataforma y de Together para evaluar su potencial en el mercado actual. Adem√°s, proporciona recomendaciones detalladas para mejorar tanto en forma como en contenido, as√≠ como una estimaci√≥n del m√°ximo de visitantes diarios que puede recibir la plataforma.

    **Funcionalidades Adicionales:**
    - **An√°lisis de Subdominios:** La aplicaci√≥n identificar√° y analizar√° autom√°ticamente todos los subdominios asociados al dominio principal proporcionado.
    """)

    # Entrada de la URL
    url_input = st.text_input("üîó Ingresa la URL de la plataforma digital que deseas analizar:", "")

    # Bot√≥n para iniciar el an√°lisis
    if st.button("‚úÖ Analizar"):
        if not url_input:
            st.error("‚ö†Ô∏è Por favor, ingresa una URL v√°lida.")
        else:
            try:
                # Validar y formatear la URL
                parsed_url = urlparse(url_input)
                if not parsed_url.scheme:
                    url_input = "https://" + url_input  # Preferir HTTPS
                    parsed_url = urlparse(url_input)

                domain = parsed_url.netloc
                if not domain:
                    st.error("‚ö†Ô∏è URL inv√°lida. Por favor, intenta nuevamente.")
                    st.stop()

                # Mostrar la URL que se analizar√°
                st.write(f"**URL a analizar:** {url_input}")

                # Verificar acceso a la URL
                try:
                    response = requests.get(url_input, timeout=10)
                    response.raise_for_status()
                except requests.exceptions.HTTPError as http_err:
                    st.error(f"‚ö†Ô∏è Error HTTP al acceder a la URL: {http_err}")
                    st.stop()
                except requests.exceptions.ConnectionError:
                    st.error("‚ö†Ô∏è Error de conexi√≥n. Verifica tu red y la URL ingresada.")
                    st.stop()
                except requests.exceptions.Timeout:
                    st.error("‚ö†Ô∏è Tiempo de espera excedido al intentar acceder a la URL.")
                    st.stop()
                except requests.exceptions.RequestException as e:
                    st.error(f"‚ö†Ô∏è Error al acceder a la URL: {e}")
                    st.stop()

                st.info("üîÑ Procesando la URL...")

                # Realizar b√∫squeda con Serper API para obtener subdominios
                serper_api_key = st.secrets["serper_api_key"]
                with st.spinner("üîç Buscando subdominios con Serper..."):
                    try:
                        subdominios = extraer_subdominios(domain, serper_api_key)
                    except requests.exceptions.HTTPError as http_err:
                        st.error(f"‚ùå Error HTTP al acceder a Serper API: {http_err}")
                        st.stop()
                    except requests.exceptions.RequestException as e:
                        st.error(f"‚ùå Error al acceder a Serper API: {e}")
                        st.stop()

                if subdominios:
                    st.success(f"‚úÖ Se encontraron {len(subdominios)} subdominio(s).")
                else:
                    st.warning("‚ö†Ô∏è No se encontraron subdominios para analizar.")

                # Agregar el dominio principal a la lista de subdominios para an√°lisis
                todos_los_dominios = [domain] + subdominios

                # Preparar una estructura para almacenar los an√°lisis
                analisis_resultados = {}

                for dom in todos_los_dominios:
                    st.write(f"### üîç **Analizando:** {dom}")
                    # Realizar b√∫squeda con Serper API para obtener informaci√≥n del dominio
                    query = f"Informaci√≥n sobre {dom}"
                    with st.spinner(f"üß† Analizando {dom} con Together..."):
                        try:
                            search_summary = obtener_busqueda_serper(query, serper_api_key)
                            if not search_summary:
                                st.warning(f"‚ö†Ô∏è No se encontr√≥ informaci√≥n relevante para {dom}.")
                                analisis_resultados[dom] = "No se encontr√≥ informaci√≥n relevante."
                                continue
                            analysis = obtener_analisis_together(search_summary, st.secrets["together_api_key"])
                            analisis_resultados[dom] = analysis
                        except requests.exceptions.HTTPError as http_err:
                            st.error(f"‚ùå Error HTTP al acceder a la API: {http_err}")
                            analisis_resultados[dom] = "Error en el an√°lisis."
                            continue
                        except requests.exceptions.RequestException as e:
                            st.error(f"‚ùå Error al acceder a la API: {e}")
                            analisis_resultados[dom] = "Error en el an√°lisis."
                            continue
                        except ValueError as ve:
                            st.error(f"‚ùå {ve}")
                            analisis_resultados[dom] = "Error en el an√°lisis."
                            continue

                    # Procesar y unificar el an√°lisis
                    # Separar el an√°lisis en secciones utilizando t√≠tulos en negrita
                    secciones = {}
                    current_section = None
                    for line in analysis.split('\n'):
                        line = line.strip()
                        match = re.match(r'\*\*(.*?)\*\*:', line)
                        if match:
                            section_title = match.group(1).strip()
                            secciones[section_title] = ""
                            current_section = section_title
                        elif current_section:
                            secciones[current_section] += line + "\n"

                    # Manejar caso sin secciones
                    if not secciones:
                        secciones["Contenido"] = analysis

                    # Generar las gr√°ficas y obtener los buffers de imagen
                    plots = generar_graficas(secciones)

                    # Mostrar el an√°lisis para el dominio/subdominio
                    with st.container():
                        st.subheader("üìä An√°lisis Unificado")
                        for titulo, contenido in secciones.items():
                            st.markdown(f"### üìå **{titulo}**")
                            st.write(contenido)

                            # Incluir visualizaciones dentro de las secciones pertinentes
                            if titulo in plots:
                                # Mostrar la gr√°fica en Streamlit
                                st.image(plots[titulo], use_column_width=True)

                                # Agregar explicaci√≥n detallada para la estimaci√≥n de visitantes diarios
                                if titulo == "Estimaci√≥n de Visitantes Diarios":
                                    st.markdown("""
                                    **¬øC√≥mo se estima el n√∫mero m√°ximo de visitantes diarios?**
                                    
                                    La estimaci√≥n de visitantes diarios se basa en un an√°lisis detallado de la plataforma digital, considerando varios factores clave que influyen en su capacidad de atraer y retener usuarios. A continuaci√≥n, se detallan los aspectos considerados para esta estimaci√≥n:
                                    
                                    1. **Optimizaci√≥n de la Usabilidad y Dise√±o:**
                                       - **Mejoras en la Interfaz de Usuario (UI):** Un dise√±o intuitivo y atractivo facilita la navegaci√≥n y mejora la experiencia del usuario, lo que puede incrementar la retenci√≥n y la recomendaci√≥n boca a boca.
                                       - **Responsive Design:** La adaptaci√≥n del sitio web a diferentes dispositivos (m√≥viles, tabletas, computadoras) asegura que una mayor audiencia pueda acceder y utilizar la plataforma sin inconvenientes.
                                    
                                    2. **Contenido Relevante y de Calidad:**
                                       - **Actualizaci√≥n Regular del Contenido:** Mantener el contenido fresco y actualizado atrae a usuarios recurrentes y mejora el posicionamiento en motores de b√∫squeda.
                                       - **SEO (Search Engine Optimization):** La optimizaci√≥n para motores de b√∫squeda incrementa la visibilidad de la plataforma, atrayendo m√°s tr√°fico org√°nico.
                                    
                                    3. **Estrategias de Marketing y Promoci√≥n:**
                                       - **Campa√±as de Marketing Digital:** Utilizar canales como redes sociales, correo electr√≥nico y publicidad pagada puede aumentar significativamente el tr√°fico hacia la plataforma.
                                       - **Colaboraciones y Alianzas Estrat√©gicas:** Asociarse con otras empresas o influencers puede ampliar la base de usuarios potenciales.
                                    
                                    4. **Funcionalidades Mejoradas:**
                                       - **Integraci√≥n de Funcionalidades Clave:** Incorporar herramientas y caracter√≠sticas que satisfagan las necesidades de los usuarios puede aumentar el tiempo de permanencia y la frecuencia de visitas.
                                       - **An√°lisis de Datos y Personalizaci√≥n:** Utilizar datos para personalizar la experiencia del usuario mejora la satisfacci√≥n y fomenta la lealtad.
                                    
                                    5. **Soporte y Atenci√≥n al Cliente:**
                                       - **Canales de Soporte Eficientes:** Ofrecer soporte r√°pido y efectivo resuelve problemas de usuarios y mejora la percepci√≥n general de la plataforma.
                                    
                                    **Conclusi√≥n:** 
                                    
                                    Al implementar las mejoras sugeridas en estos aspectos, se espera que la plataforma digital no solo aumente su atractivo y funcionalidad, sino que tambi√©n mejore su capacidad para atraer y retener un mayor n√∫mero de visitantes diarios. La combinaci√≥n de un dise√±o optimizado, contenido de calidad, estrategias de marketing efectivas y funcionalidades avanzadas contribuye significativamente a la estimaci√≥n del n√∫mero m√°ximo de visitantes diarios.
                                    """)

    # Ejecutar la aplicaci√≥n
    if __name__ == "__main__":
    main()

