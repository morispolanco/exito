import streamlit as st
import requests
from urllib.parse import urlparse
import re

def main():
    # T√≠tulo de la aplicaci√≥n
    st.title("üìà An√°lisis de Potencial de √âxito de Plataformas Digitales")

    # Descripci√≥n de la aplicaci√≥n
    st.markdown("""
    Esta aplicaci√≥n analiza el potencial de √©xito de una plataforma digital basada en su URL. Utiliza las APIs de Serper para obtener informaci√≥n relevante sobre la plataforma y de Together para evaluar su potencial en el mercado actual. Adem√°s, proporciona recomendaciones detalladas para mejorar tanto en forma como en contenido, as√≠ como una estimaci√≥n del m√°ximo de visitantes diarios que puede recibir la plataforma.

    **Funcionalidades Adicionales:**
    - **An√°lisis de Subdominios:** La aplicaci√≥n identificar√° y analizar√° autom√°ticamente todos los subdominios asociados al dominio principal proporcionado.
    """)

    # Entrada de la URL
    url_input = st.text_input("üîó Ingresa la URL de la plataforma digital que deseas analizar:", "")

    # Bot√≥n para iniciar el an√°lisis
    if st.button("‚úÖ Analizar"):
        if not url_input:
            st.error("‚ö†Ô∏è Por favor, ingresa una URL v√°lida.")
        else:
            try:
                # Validar y formatear la URL
                parsed_url = urlparse(url_input)
                if not parsed_url.scheme:
                    url_input = "https://" + url_input  # Preferir HTTPS
                    parsed_url = urlparse(url_input)

                domain = parsed_url.netloc
                if not domain:
                    st.error("‚ö†Ô∏è URL inv√°lida. Por favor, intenta nuevamente.")
                    st.stop()

                # Mostrar la URL que se analizar√°
                st.write(f"**URL a analizar:** {url_input}")

                # Verificar acceso a la URL
                try:
                    response = requests.get(url_input, timeout=10)
                    response.raise_for_status()
                except requests.exceptions.HTTPError as http_err:
                    st.error(f"‚ö†Ô∏è Error HTTP al acceder a la URL: {http_err}")
                    st.stop()
                except requests.exceptions.ConnectionError:
                    st.error("‚ö†Ô∏è Error de conexi√≥n. Verifica tu red y la URL ingresada.")
                    st.stop()
                except requests.exceptions.Timeout:
                    st.error("‚ö†Ô∏è Tiempo de espera excedido al intentar acceder a la URL.")
                    st.stop()
                except requests.exceptions.RequestException as e:
                    st.error(f"‚ö†Ô∏è Error al acceder a la URL: {e}")
                    st.stop()

                st.info("üîÑ Procesando la URL...")

                # Realizar b√∫squeda con Serper API para obtener subdominios
                serper_api_key = st.secrets["serper_api_key"]
                with st.spinner("üîç Buscando subdominios con Serper..."):
                    try:
                        subdominios = extraer_subdominios(domain, serper_api_key)
                    except requests.exceptions.HTTPError as http_err:
                        st.error(f"‚ùå Error HTTP al acceder a Serper API: {http_err}")
                        st.stop()
                    except requests.exceptions.RequestException as e:
                        st.error(f"‚ùå Error al acceder a Serper API: {e}")
                        st.stop()

                if subdominios:
                    st.success(f"‚úÖ Se encontraron {len(subdominios)} subdominio(s).")
                else:
                    st.warning("‚ö†Ô∏è No se encontraron subdominios para analizar.")

                # Agregar el dominio principal a la lista de subdominios para an√°lisis
                todos_los_dominios = [domain] + subdominios

                # Preparar una estructura para almacenar los an√°lisis
                analisis_resultados = {}

                for dom in todos_los_dominios:
                    st.write(f"### üîç **Analizando:** {dom}")
                    # Realizar b√∫squeda con Serper API para obtener informaci√≥n del dominio
                    query = f"Informaci√≥n sobre {dom}"
                    with st.spinner(f"üß† Analizando {dom} con Together..."):
                        try:
                            search_summary = obtener_busqueda_serper(query, serper_api_key)
                            if not search_summary:
                                st.warning(f"‚ö†Ô∏è No se encontr√≥ informaci√≥n relevante para {dom}.")
                                analisis_resultados[dom] = "No se encontr√≥ informaci√≥n relevante."
                                continue
                            analysis = obtener_analisis_together(search_summary, st.secrets["together_api_key"])
                            analisis_resultados[dom] = analysis
                        except requests.exceptions.HTTPError as http_err:
                            st.error(f"‚ùå Error HTTP al acceder a la API: {http_err}")
                            analisis_resultados[dom] = "Error en el an√°lisis."
                            continue
                        except requests.exceptions.RequestException as e:
                            st.error(f"‚ùå Error al acceder a la API: {e}")
                            analisis_resultados[dom] = "Error en el an√°lisis."
                            continue
                        except ValueError as ve:
                            st.error(f"‚ùå {ve}")
                            analisis_resultados[dom] = "Error en el an√°lisis."
                            continue

                    # Procesar y unificar el an√°lisis
                    # Separar el an√°lisis en secciones utilizando t√≠tulos en negrita
                    secciones = {}
                    current_section = None
                    for line in analysis.split('\n'):
                        line = line.strip()
                        match = re.match(r'\*\*(.*?)\*\*:', line)
                        if match:
                            section_title = match.group(1).strip()
                            secciones[section_title] = ""
                            current_section = section_title
                        elif current_section:
                            secciones[current_section] += line + "\n"

                    # Manejar caso sin secciones
                    if not secciones:
                        secciones["Contenido"] = analysis

                    # Generar las gr√°ficas y obtener los buffers de imagen
                    plots = generar_graficas(secciones)

                    # Mostrar el an√°lisis para el dominio/subdominio
                    with st.container():
                        st.subheader("üìä An√°lisis Unificado")
                        for titulo, contenido in secciones.items():
                            st.markdown(f"### üìå **{titulo}**")
                            st.write(contenido)

                            # Incluir visualizaciones dentro de las secciones pertinentes
                            if titulo in plots:
                                # Mostrar la gr√°fica en Streamlit
                                st.image(plots[titulo], use_column_width=True)

                                # Agregar explicaci√≥n detallada para la estimaci√≥n de visitantes diarios
                                if titulo == "Estimaci√≥n de Visitantes Diarios":
                                    st.markdown("""
                                    **¬øC√≥mo se estima el n√∫mero m√°ximo de visitantes diarios?**
                                    """)
            except Exception as e:
                st.error(f"‚ùå Se produjo un error inesperado: {str(e)}")

if __name__ == "__main__":
    main()
