import streamlit as st
import requests
from urllib.parse import urlparse
import matplotlib.pyplot as plt
import re
from io import BytesIO
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.enum.text import PP_ALIGN
from PIL import Image

# ============================================
# Funciones Auxiliares
# ============================================

def parse_number(text):
    """
    Funci√≥n para parsear n√∫meros con diferentes formatos.
    Convierte cadenas de texto a n√∫meros flotantes.
    """
    text = re.sub(r'[^\d.,]', '', text)
    if text.count(',') > text.count('.'):
        text = text.replace('.', '').replace(',', '.')
    else:
        text = text.replace(',', '')
    try:
        return float(text)
    except ValueError:
        return None

@st.cache_data(show_spinner=False)
def obtener_busqueda_serper(query, api_key):
    """
    Funci√≥n para obtener resultados de b√∫squeda utilizando la API de Serper.
    """
    serper_url = "https://google.serper.dev/search"
    headers_serper = {
        "X-API-KEY": api_key,
        "Content-Type": "application/json"
    }
    data_serper = {"q": query}
    response_serper = requests.post(serper_url, headers=headers_serper, json=data_serper, timeout=10)
    response_serper.raise_for_status()
    search_results = response_serper.json()
    snippets = []
    if "organic" in search_results:
        for item in search_results["organic"]:
            if "snippet" in item:
                snippets.append(item["snippet"])
    return "\n\n".join(snippets) if snippets else "No se encontraron resultados relevantes."

@st.cache_data(show_spinner=False)
def obtener_analisis_together(search_summary, api_key):
    """
    Funci√≥n para obtener an√°lisis detallado utilizando la API de Together.
    """
    together_url = "https://api.together.xyz/v1/chat/completions"
    headers_together = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    messages = [
        {
            "role": "system",
            "content": (
                "Eres un experto en an√°lisis de plataformas digitales con un enfoque en las demandas del mercado actual. "
                "Proporciona una evaluaci√≥n detallada del potencial de √©xito de la plataforma digital basada en la siguiente informaci√≥n. "
                "Incluye recomendaciones sobre aspectos de forma (dise√±o, usabilidad, interfaz) y fondo (funcionalidades, contenido, estrategia de mercado), se√±alando lo que sobra y lo que falta. "
                "Adem√°s, expresa el potencial de √©xito en t√©rminos de porcentaje, proporciona una estimaci√≥n del m√°ximo de visitantes al d√≠a y un resumen ejecutivo de los hallazgos clave."
                "\n\n"
                "Nota: La estimaci√≥n de visitantes diarios se basa en la versi√≥n mejorada de la plataforma, incorporando los cambios sugeridos."
            )
        },
        {
            "role": "user",
            "content": f"Aqu√≠ hay informaci√≥n sobre la plataforma: {search_summary}"
        }
    ]
    data_together = {
        "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "messages": messages,
        "max_tokens": 2512,
        "temperature": 0.7,
        "top_p": 0.7,
        "top_k": 50,
        "repetition_penalty": 1,
        "stop": ["<|eot_id|>"],
        "stream": False
    }

    response_together = requests.post(together_url, headers=headers_together, json=data_together, timeout=30)
    response_together.raise_for_status()
    analysis = response_together.json()
    if "choices" in analysis and len(analysis["choices"]) > 0:
        return analysis["choices"][0]["message"]["content"]
    else:
        raise ValueError("Respuesta inesperada de Together API.")

def generar_graficas(secciones):
    """
    Funci√≥n para generar las gr√°ficas necesarias basadas en las secciones del an√°lisis.
    Retorna un diccionario con el t√≠tulo de la secci√≥n y el buffer de la imagen.
    """
    plots = {}
    # Potencial de √âxito
    if "Potencial de √âxito" in secciones:
        porcentaje_val = parse_number(secciones["Potencial de √âxito"])
        if porcentaje_val is not None:
            fig, ax = plt.subplots(figsize=(2, 2))
            ax.pie([porcentaje_val, 100 - porcentaje_val], colors=['#4CAF50', '#CCCCCC'], startangle=90, counterclock=False)
            ax.axis('equal')
            buf = BytesIO()
            plt.savefig(buf, format='png', bbox_inches='tight')
            plt.close(fig)
            buf.seek(0)
            plots["Potencial de √âxito"] = buf

    # Estimaci√≥n de Visitantes Diarios
    if "Estimaci√≥n de Visitantes Diarios" in secciones:
        est_visitors_val = parse_number(secciones["Estimaci√≥n de Visitantes Diarios"])
        if est_visitors_val is not None:
            est_visitors_val = int(est_visitors_val)
            fig, ax = plt.subplots(figsize=(4, 1))
            ax.barh([''], [est_visitors_val], color='#4CAF50')
            ax.set_xlim(0, est_visitors_val * 1.2)
            ax.set_xlabel('N√∫mero de Visitantes')
            ax.set_yticks([])
            plt.tight_layout()
            buf = BytesIO()
            plt.savefig(buf, format='png', bbox_inches='tight')
            plt.close(fig)
            buf.seek(0)
            plots["Estimaci√≥n de Visitantes Diarios"] = buf

    return plots

def generar_pptx(secciones, plots):
    """
    Funci√≥n para generar una presentaci√≥n de PowerPoint (PPTX) con el an√°lisis y las gr√°ficas.
    Divide el an√°lisis en varias diapositivas, una por cada secci√≥n.
    Retorna un buffer con el archivo PPTX.
    """
    prs = Presentation()
    
    # Dise√±o de diapositiva: T√≠tulo y contenido
    slide_layout_title = prs.slide_layouts[0]  # T√≠tulo
    slide_layout_content = prs.slide_layouts[1]  # T√≠tulo y contenido

    # Diapositiva de T√≠tulo
    slide_title = prs.slides.add_slide(slide_layout_title)
    title = slide_title.shapes.title
    title.text = "An√°lisis de Potencial de √âxito"

    # Iterar sobre las secciones y a√±adir diapositivas
    for titulo, contenido in secciones.items():
        slide = prs.slides.add_slide(slide_layout_content)
        title = slide.shapes.title
        body = slide.placeholders[1]

        title.text = titulo

        # Agregar el contenido de la secci√≥n
        tf = body.text_frame
        tf.word_wrap = True
        p = tf.add_paragraph()
        p.text = contenido
        p.font.size = Pt(12)

        # A√±adir gr√°fica si existe
        if titulo in plots:
            img_buffer = plots[titulo]
            img = Image.open(img_buffer)
            img_path = f"{titulo}.png"
            img.save(img_path)

            # Insertar la imagen en la diapositiva
            left = Inches(1)
            top = Inches(3)
            height = Inches(3)
            slide.shapes.add_picture(img_path, left, top, height=height)

    # Guardar la presentaci√≥n en un buffer
    buffer = BytesIO()
    prs.save(buffer)
    buffer.seek(0)
    return buffer

# ============================================
# Aplicaci√≥n Streamlit
# ============================================

def main():
    # T√≠tulo de la aplicaci√≥n
    st.title("üìà An√°lisis de Potencial de √âxito de Plataformas Digitales")

    # Descripci√≥n de la aplicaci√≥n
    st.markdown("""
    Esta aplicaci√≥n analiza el potencial de √©xito de una plataforma digital basada en su URL. Utiliza las APIs de Serper para obtener informaci√≥n relevante sobre la plataforma y de Together para evaluar su potencial en el mercado actual. Adem√°s, proporciona recomendaciones detalladas para mejorar tanto en forma como en contenido, as√≠ como una estimaci√≥n del m√°ximo de visitantes diarios que puede recibir la plataforma.
    """)

    # Entrada de la URL
    url_input = st.text_input("üîó Ingresa la URL de la plataforma digital que deseas analizar:", "")

    # Bot√≥n para iniciar el an√°lisis
    if st.button("‚úÖ Analizar"):
        if not url_input:
            st.error("‚ö†Ô∏è Por favor, ingresa una URL v√°lida.")
        else:
            # Validar y formatear la URL
            parsed_url = urlparse(url_input)
            if not parsed_url.scheme:
                url_input = "https://" + url_input  # Preferir HTTPS
                parsed_url = urlparse(url_input)

            domain = parsed_url.netloc
            if not domain:
                st.error("‚ö†Ô∏è URL inv√°lida. Por favor, intenta nuevamente.")
                st.stop()

            try:
                response = requests.get(url_input, timeout=10)
                response.raise_for_status()
            except requests.exceptions.HTTPError as http_err:
                st.error(f"‚ö†Ô∏è Error HTTP al acceder a la URL: {http_err}")
                st.stop()
            except requests.exceptions.ConnectionError:
                st.error("‚ö†Ô∏è Error de conexi√≥n. Verifica tu red y la URL ingresada.")
                st.stop()
            except requests.exceptions.Timeout:
                st.error("‚ö†Ô∏è Tiempo de espera excedido al intentar acceder a la URL.")
                st.stop()
            except requests.exceptions.RequestException as e:
                st.error(f"‚ö†Ô∏è Error al acceder a la URL: {e}")
                st.stop()

            st.info("üîÑ Procesando la URL...")

            # Realizar b√∫squeda con Serper API
            serper_api_key = st.secrets["serper_api_key"]
            query = f"Informaci√≥n sobre {domain}"

            with st.spinner("üîç Realizando b√∫squeda con Serper..."):
                try:
                    search_summary = obtener_busqueda_serper(query, serper_api_key)
                except requests.exceptions.HTTPError as http_err:
                    st.error(f"‚ùå Error HTTP al acceder a Serper API: {http_err}")
                    st.stop()
                except requests.exceptions.RequestException as e:
                    st.error(f"‚ùå Error al acceder a Serper API: {e}")
                    st.stop()

            # Preparar el mensaje para Together API
            together_api_key = st.secrets["together_api_key"]

            with st.spinner("üß† Analizando con Together..."):
                try:
                    result = obtener_analisis_together(search_summary, together_api_key)
                except requests.exceptions.HTTPError as http_err:
                    st.error(f"‚ùå Error HTTP al acceder a Together API: {http_err}")
                    st.stop()
                except requests.exceptions.RequestException as e:
                    st.error(f"‚ùå Error al acceder a Together API: {e}")
                    st.stop()
                except ValueError as ve:
                    st.error(f"‚ùå {ve}")
                    st.stop()

            # Procesar y unificar el an√°lisis
            # Separar el an√°lisis en secciones utilizando t√≠tulos en negrita
            secciones = {}
            current_section = None
            for line in result.split('\n'):
                line = line.strip()
                match = re.match(r'\*\*(.*?)\*\*:', line)
                if match:
                    section_title = match.group(1).strip()
                    secciones[section_title] = ""
                    current_section = section_title
                elif current_section:
                    secciones[current_section] += line + "\n"

            # Manejar caso sin secciones
            if not secciones:
                secciones["Contenido"] = result

            # Generar las gr√°ficas y obtener los buffers de imagen
            plots = generar_graficas(secciones)

            # Crear un contenedor para unificar el an√°lisis
            with st.container():
                st.subheader("üìä An√°lisis Unificado")
                for titulo, contenido in secciones.items():
                    st.markdown(f"### üìå **{titulo}**")
                    st.write(contenido)

                    # Incluir visualizaciones dentro de las secciones pertinentes
                    if titulo in plots:
                        # Mostrar la gr√°fica en Streamlit
                        st.image(plots[titulo], use_column_width=True)

                        # Agregar explicaci√≥n detallada para la estimaci√≥n de visitantes diarios
                        if titulo == "Estimaci√≥n de Visitantes Diarios":
                            st.markdown("""
                            **¬øC√≥mo se estima el n√∫mero m√°ximo de visitantes diarios?**
                            
                            La estimaci√≥n de visitantes diarios se basa en un an√°lisis detallado de la plataforma digital, considerando varios factores clave que influyen en su capacidad de atraer y retener usuarios. A continuaci√≥n, se detallan los aspectos considerados para esta estimaci√≥n:
                            
                            1. **Optimizaci√≥n de la Usabilidad y Dise√±o:**
                               - **Mejoras en la Interfaz de Usuario (UI):** Un dise√±o intuitivo y atractivo facilita la navegaci√≥n y mejora la experiencia del usuario, lo que puede incrementar la retenci√≥n y la recomendaci√≥n boca a boca.
                               - **Responsive Design:** La adaptaci√≥n del sitio web a diferentes dispositivos (m√≥viles, tabletas, computadoras) asegura que una mayor audiencia pueda acceder y utilizar la plataforma sin inconvenientes.
                            
                            2. **Contenido Relevante y de Calidad:**
                               - **Actualizaci√≥n Regular del Contenido:** Mantener el contenido fresco y actualizado atrae a usuarios recurrentes y mejora el posicionamiento en motores de b√∫squeda.
                               - **SEO (Search Engine Optimization):** La optimizaci√≥n para motores de b√∫squeda incrementa la visibilidad de la plataforma, atrayendo m√°s tr√°fico org√°nico.
                            
                            3. **Estrategias de Marketing y Promoci√≥n:**
                               - **Campa√±as de Marketing Digital:** Utilizar canales como redes sociales, correo electr√≥nico y publicidad pagada puede aumentar significativamente el tr√°fico hacia la plataforma.
                               - **Colaboraciones y Alianzas Estrat√©gicas:** Asociarse con otras empresas o influencers puede ampliar la base de usuarios potenciales.
                            
                            4. **Funcionalidades Mejoradas:**
                               - **Integraci√≥n de Funcionalidades Clave:** Incorporar herramientas y caracter√≠sticas que satisfagan las necesidades de los usuarios puede aumentar el tiempo de permanencia y la frecuencia de visitas.
                               - **An√°lisis de Datos y Personalizaci√≥n:** Utilizar datos para personalizar la experiencia del usuario mejora la satisfacci√≥n y fomenta la lealtad.
                            
                            5. **Soporte y Atenci√≥n al Cliente:**
                               - **Canales de Soporte Eficientes:** Ofrecer soporte r√°pido y efectivo resuelve problemas de usuarios y mejora la percepci√≥n general de la plataforma.
                            
                            **Conclusi√≥n:**
                            
                            Al implementar las mejoras sugeridas en estos aspectos, se espera que la plataforma digital no solo aumente su atractivo y funcionalidad, sino que tambi√©n mejore su capacidad para atraer y retener un mayor n√∫mero de visitantes diarios. La combinaci√≥n de un dise√±o optimizado, contenido de calidad, estrategias de marketing efectivas y funcionalidades avanzadas contribuye significativamente a la estimaci√≥n del n√∫mero m√°ximo de visitantes diarios.
                            """)

            # Generar la presentaci√≥n PPTX
            with st.spinner("üìä Generando presentaci√≥n PPTX..."):
                pptx_buffer = generar_pptx(secciones, plots)

            # Bot√≥n para descargar el PPTX
            st.download_button(
                label="üì• Descargar An√°lisis en PPTX",
                data=pptx_buffer,
                file_name="analisis_plataforma.pptx",
                mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
            )

# Ejecutar la aplicaci√≥n
if __name__ == "__main__":
    main()
