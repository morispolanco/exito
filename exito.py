import streamlit as st
import requests
from urllib.parse import urlparse
import matplotlib.pyplot as plt
import re

# Funci√≥n para parsear n√∫meros con diferentes formatos
def parse_number(text):
    text = re.sub(r'[^\d.,]', '', text)
    if text.count(',') > text.count('.'):
        text = text.replace('.', '').replace(',', '.')
    else:
        text = text.replace(',', '')
    try:
        return float(text)
    except ValueError:
        return None

# Funci√≥n para obtener resultados de Serper con cach√©
@st.cache_data(show_spinner=False)
def obtener_busqueda_serper(query, api_key):
    serper_url = "https://google.serper.dev/search"
    headers_serper = {
        "X-API-KEY": api_key,
        "Content-Type": "application/json"
    }
    data_serper = {"q": query}
    response_serper = requests.post(serper_url, headers=headers_serper, json=data_serper, timeout=10)
    response_serper.raise_for_status()
    search_results = response_serper.json()
    snippets = []
    if "organic" in search_results:
        for item in search_results["organic"]:
            if "snippet" in item:
                snippets.append(item["snippet"])
    return "\n\n".join(snippets) if snippets else "No se encontraron resultados relevantes."

# Funci√≥n para obtener an√°lisis de Together con cach√©
@st.cache_data(show_spinner=False)
def obtener_analisis_together(search_summary, api_key):
    together_url = "https://api.together.xyz/v1/chat/completions"
    headers_together = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    messages = [
        {
            "role": "system",
            "content": (
                "Eres un experto en an√°lisis de plataformas digitales con un enfoque en las demandas del mercado actual. "
                "Proporciona una evaluaci√≥n detallada del potencial de √©xito de la plataforma digital basada en la siguiente informaci√≥n. "
                "Incluye recomendaciones sobre aspectos de forma (dise√±o, usabilidad, interfaz) y fondo (funcionalidades, contenido, estrategia de mercado), se√±alando lo que sobra y lo que falta. "
                "Adem√°s, expresa el potencial de √©xito en t√©rminos de porcentaje, proporciona una estimaci√≥n del m√°ximo de visitantes al d√≠a y un resumen ejecutivo de los hallazgos clave."
            )
        },
        {
            "role": "user",
            "content": f"Aqu√≠ hay informaci√≥n sobre la plataforma: {search_summary}"
        }
    ]
    data_together = {
        "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "messages": messages,
        "max_tokens": 2512,
        "temperature": 0.7,
        "top_p": 0.7,
        "top_k": 50,
        "repetition_penalty": 1,
        "stop": ["<|eot_id|>"],
        "stream": False
    }

    response_together = requests.post(together_url, headers=headers_together, json=data_together, timeout=30)
    response_together.raise_for_status()
    analysis = response_together.json()
    if "choices" in analysis and len(analysis["choices"]) > 0:
        return analysis["choices"][0]["message"]["content"]
    else:
        raise ValueError("Respuesta inesperada de Together API.")

# T√≠tulo de la aplicaci√≥n
st.title("üìà An√°lisis de Potencial de √âxito de Plataformas Digitales")

# Descripci√≥n de la aplicaci√≥n
st.markdown("""
Esta aplicaci√≥n analiza el potencial de √©xito de una plataforma digital basada en su URL. Utiliza las APIs de Serper para obtener informaci√≥n relevante sobre la plataforma y de Together para evaluar su potencial en el mercado actual. Adem√°s, proporciona recomendaciones detalladas para mejorar tanto en forma como en contenido, as√≠ como una estimaci√≥n del m√°ximo de visitantes diarios que puede recibir la plataforma.
""")

# Entrada de la URL
url_input = st.text_input("üîó Ingresa la URL de la plataforma digital que deseas analizar:", "")

# Bot√≥n para iniciar el an√°lisis
if st.button("‚úÖ Analizar"):
    if not url_input:
        st.error("‚ö†Ô∏è Por favor, ingresa una URL v√°lida.")
    else:
        # Validar y formatear la URL
        parsed_url = urlparse(url_input)
        if not parsed_url.scheme:
            url_input = "https://" + url_input  # Preferir HTTPS
            parsed_url = urlparse(url_input)

        domain = parsed_url.netloc
        if not domain:
            st.error("‚ö†Ô∏è URL inv√°lida. Por favor, intenta nuevamente.")
            st.stop()

        try:
            response = requests.get(url_input, timeout=10)
            response.raise_for_status()
        except requests.exceptions.HTTPError as http_err:
            st.error(f"‚ö†Ô∏è Error HTTP al acceder a la URL: {http_err}")
            st.stop()
        except requests.exceptions.ConnectionError:
            st.error("‚ö†Ô∏è Error de conexi√≥n. Verifica tu red y la URL ingresada.")
            st.stop()
        except requests.exceptions.Timeout:
            st.error("‚ö†Ô∏è Tiempo de espera excedido al intentar acceder a la URL.")
            st.stop()
        except requests.exceptions.RequestException as e:
            st.error(f"‚ö†Ô∏è Error al acceder a la URL: {e}")
            st.stop()

        st.info("üîÑ Procesando la URL...")

        # Realizar b√∫squeda con Serper API
        serper_api_key = st.secrets["serper_api_key"]
        query = f"Informaci√≥n sobre {domain}"

        with st.spinner("üîç Realizando b√∫squeda con Serper..."):
            try:
                search_summary = obtener_busqueda_serper(query, serper_api_key)
            except requests.exceptions.HTTPError as http_err:
                st.error(f"‚ùå Error HTTP al acceder a Serper API: {http_err}")
                st.stop()
            except requests.exceptions.RequestException as e:
                st.error(f"‚ùå Error al acceder a Serper API: {e}")
                st.stop()

        # Preparar el mensaje para Together API
        together_api_key = st.secrets["together_api_key"]

        with st.spinner("üß† Analizando con Together..."):
            try:
                result = obtener_analisis_together(search_summary, together_api_key)
            except requests.exceptions.HTTPError as http_err:
                st.error(f"‚ùå Error HTTP al acceder a Together API: {http_err}")
                st.stop()
            except requests.exceptions.RequestException as e:
                st.error(f"‚ùå Error al acceder a Together API: {e}")
                st.stop()
            except ValueError as ve:
                st.error(f"‚ùå {ve}")
                st.stop()

        # Procesar y unificar el an√°lisis
        # Separar el an√°lisis en secciones utilizando t√≠tulos en negrita
        secciones = {}
        current_section = None
        for line in result.split('\n'):
            line = line.strip()
            match = re.match(r'\*\*(.*?)\*\*:', line)
            if match:
                section_title = match.group(1).strip()
                secciones[section_title] = ""
                current_section = section_title
            elif current_section:
                secciones[current_section] += line + "\n"

        # Manejar caso sin secciones
        if not secciones:
            secciones["Contenido"] = result

        # Depuraci√≥n: Mostrar las secciones detectadas (opcional)
        # st.subheader("üîç Secciones Detectadas")
        # st.write(list(secciones.keys()))

        # Crear un contenedor para unificar el an√°lisis
        with st.container():
            st.subheader("üìä An√°lisis Unificado")
            for titulo, contenido in secciones.items():
                st.markdown(f"### üìå **{titulo}**")
                st.write(contenido)

                # Incluir visualizaciones dentro de las secciones pertinentes
                if titulo == "Potencial de √âxito":
                    porcentaje_val = parse_number(contenido)
                    if porcentaje_val is not None:
                        fig, ax = plt.subplots(figsize=(2, 2))
                        ax.pie([porcentaje_val, 100 - porcentaje_val], colors=['#4CAF50', '#CCCCCC'], startangle=90, counterclock=False)
                        ax.axis('equal')
                        st.pyplot(fig)
                        st.markdown(f"**Potencial de √âxito: {porcentaje_val}%**")
                elif titulo == "Estimaci√≥n de Visitantes Diarios":
                    est_visitors_val = parse_number(contenido)
                    if est_visitors_val is not None:
                        est_visitors_val = int(est_visitors_val)
                        st.metric(label="M√°ximo de Visitantes al D√≠a", value=f"{est_visitors_val:,}")
                        fig, ax = plt.subplots(figsize=(4, 1))
                        ax.barh([''], [est_visitors_val], color='#4CAF50')
                        ax.set_xlim(0, est_visitors_val * 1.2)
                        ax.set_xlabel('N√∫mero de Visitantes')
                        ax.set_yticks([])
                        st.pyplot(fig)

        st.success("‚úÖ An√°lisis completado:")
        st.write(result)
